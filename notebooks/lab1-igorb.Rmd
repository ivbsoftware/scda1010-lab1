---
title: "CSDA1010SUMA18 - LAB EXERCISE 1: Classification Problem"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Ctrl+Shift+Enter*. 

```{r}
library(readr)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(Amelia)
library(rattle)
library(RColorBrewer)
library(caret)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

## Nursery Data Set reference and short description

Source: http://archive.ics.uci.edu/ml/datasets/Nursery

```
| class values

not_recom, recommend, very_recom, priority, spec_prior

| attributes

parents:     usual, pretentious, great_pret.
has_nurs:    proper, less_proper, improper, critical, very_crit.
form:        complete, completed, incomplete, foster.
children:    1, 2, 3, more.
housing:     convenient, less_conv, critical.
finance:     convenient, inconv.
social:      nonprob, slightly_prob, problematic.
health:      recommended, priority, not_recom.
```


```{r}
nursery_data <- read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data", header = FALSE, col.names = c("parents","has_nurs","form","children","housing","finance","social","health","class"))
```

## Data Set exploration and cleaning
```{r}
head(nursery_data)
str(nursery_data)
```
## Splitting the dataset into train and test based on outcome (class)
The Nursing dataset has the following distribution of outcome parameter:
```{r}
prop.table((table(nursery_data$class)))
```

We are splitting the dataset in such a way, that train and test sets would have similar distribution of the 'class' attribute. 
The train set will contain 75% of all data.
```{r}
train.rows<- createDataPartition(y= nursery_data$class, p=0.75, list = FALSE)
train.data<- nursery_data[train.rows,] # 75% data goes in here
prop.table((table(train.data$class)))
```

Now creating and checking the test set containing 25% of the data
```{r}
test.data<- nursery_data[-train.rows,] # 25% data goes in here
prop.table((table(test.data$class)))
```

Note that test set has not get any  rows with 'recommend' outcome. The reson of this is that there were only 2 occurences of those rows in the whole set and they both were picked to the train set.

## Iterative data model fit and evaluation

### Interation 1: Decision Tree model fit
```{r}
fitdt <- rpart(class~., method="class", data=train.data)
```
```{r fig.width=8, message=FALSE, warning=FALSE, paged.print=TRUE}
fancyRpartPlot(fitdt)
```
```{r}
dtPrediction <- predict(fitdt, test.data)
head(dtPrediction,n=15)
head(test.data,n=15)
```
To estimate the quality of the prediction first we create a dataframe with 2 columns - 'original' value of 'class' in the test dataset and 'prediction', which is a name of the column of dtPrediction object with the max probalility value in the row (look at dtPrediction object above).
```{r Original vs predicted values of test dataset}
dtPredictedClass <-data.frame(original=test.data$class, prediction=colnames(dtPrediction)[apply(dtPrediction,1,which.max)], row.names = rownames(test.data))
head(dtPredictedClass, n=200)
```
 

```{r}
 confusionMatrix(data=dtPredictedClass$prediction,dtPredictedClass$original)
```
 

