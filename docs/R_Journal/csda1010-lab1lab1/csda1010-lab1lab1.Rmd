---
title: Ranking Applications for Nursery Schools

author: 
  - name          : "Viviane Adohouannon"
    affiliation   : "York University School of Continious Studies"
    email         : "https://learn.continue.yorku.ca/user/view.php?id=21444"  
  - name          : "Kate Alexander"
    affiliation   : "York University School of Continious Studies"
    email         : "https://learn.continue.yorku.ca/user/view.php?id=21524"    
  - name          : "Diana Azbel"
    affiliation   : "York University School of Continious Studies"
    email         : "https://learn.continue.yorku.ca/user/view.php?id=20687"  
  - name          : "Igor Baranov"
    affiliation   : "York University School of Continious Studies"
    email         : "https://learn.continue.yorku.ca/user/profile.php?id=21219"  

Abstract: >
The speciﬁc problem under consideration is to rank selection of applicants for nursery schools in Ljubljana, Slovenia in the 1980's. 
Nursery Database was derived from a hierarchical decision model originally developed to rank applications. A classification model has been used to developed a reliable recomendation algorithm to predict if a specific applicant is a suitable candidate to be addmitted into a nursery school. 

output:
  rticles::rjournal_article:
    includes:
      in_header: preamble.tex
---

# Introduction
Malala Yousafzai once said, “Let us remember: One book, one pen, one child, and one teacher can change the world.” Education is important because it gives people the skills of basic literacy and numeracy, as well as the ability to communicate, complete tasks and work with others. 

Early schooling such as Nursery school education matters most as it impacts children's long-term development and academic progress. While all children benefit from a high-quality nursery school, family structure, social and financial standing, and proximity to schools may affect the enrollment process. 

Nursery Database was derived from a hierarchical decision model originally developed to rank applications for nursery schools. It was used during several years in 1980's when there was excessive enrollment to these schools in Ljubljana, Slovenia, and the rejected applications frequently needed an objective explanation.
Source: http://archive.ics.uci.edu/ml/datasets/Nursery

## Background
Ljubljana is the capital and largest city of Slovenia. The city with an area of 163.8 square kilometers is situated in the Ljubljana Basin in Central Slovenia, between the Alps and the Karst. Ljubljana is located some 320 kilometers south of Munich, 477 kilometers  east of Zürich. In 1981 the population of the city rose to 224,817 inhabients with approximately 91% of the population speak Slovene as their primary native language. The second most-spoken language is Bosnian, with Serbo-Croatian being the third most-spoken language.
Source: https://en.wikipedia.org/wiki/Ljubljana

During this time "new housing developments populated by young families, the demand for children’s admission in nursery schools outstrips supply,    notwithstanding the fast growth rate of new schools. This general problem was exempliﬁed in a particular Ljubljana district where    there were approximately 600 applicants for 300 spaces to be considered by the Acceptance Committee in the local nursery school each year."

Source: http://kt.ijs.si/MarkoBohanec/pub/Nursery89.pdf
M. Olave, V. Rajkovic, M. Bohanec: An application for admission in public school systems. In (I. Th. M. Snellen and W. B. H. J. van de Donk and J.-P. Baquiast, editors) Expert Systems in Public Administration, pages 145-160. Elsevier Science Publishers (North Holland), 1989.

## Objective and Hypothesis

The objective is to provide a reliable recommendation algorithm to predict if a specific applicant is a suitable candidate to be admitted into a nursery school or if the applicate should stay with their parents. The results of this recommendation may affect the child’s engagement within the school, parents’ involvement in school activities and overall satisfaction of the applicants long-term academic progress.

The most important decisions depended on three sub-problems: 
  - Occupation of parents and child's nursery;
  - Family structure and financial standing; 
  - Social and health picture of the family. 
  
## Assessment of Situation
The following tables present the input attributes description with their structure:

##Table 1: Variables description

##Table 2: Target variables description

Number of Attributes: 8, Number of Instances: 12960

From the data snapshot, 33% of nursery school applications ended not being recommended because of multiple reasons. However some of the applications that were recommended came from parents having good health conditions (67%) and some applications have really good social conditions contributed by 33% of the parents nursery applications being recommended.

##Frequency Table: Targeted variable

##Frequency Table: Targeted variable vs attributes


## Plan
Et harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod:

 - Cras sit amet lacus luctus massa lobortis sagittis.
 - Curabitur convallis nisi non fringilla mattis.
 - Etiam auctor massa nec orci hendrerit convallis.
 - Nunc et tortor eu nisl gravida tempor a a lorem.
 - Morbi sit amet sem posuere, aliquam ex ut, lacinia nulla.

# Data understanding
Harum quidem rerum facilis est et expedita distinctio. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod.

## Preparation
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
set.seed(42)
library(readr)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(Amelia)
library(rattle)
library(RColorBrewer)
library(caret)
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
library(xtable)
options(xtable.floating = TRUE)
options(xtable.timestamp = "")
options(xtable.comment = FALSE)
```


```{r eval=FALSE, include=FALSE}
nursery_data <- 
  read.csv("http://archive.ics.uci.edu/ml/machine-learning-databases/nursery/nursery.data", 
  header = FALSE, 
  col.names = c("parents","has_nurs","form",
                "children","housing","finance",
                "social","health","class"))
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
nursery_data <- read.csv(file = "../../../data/nursery_data.csv")
```

```{r echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
dh.rescale <- xtable(head(nursery_data, n=10), caption = "\\tt Nursery Data Dataset (head)")
print(dh.rescale, scalebox=.75)
```

Summary of Nursery Data set is extracted by the folloving 'summary' function, the results are presented in Table \ref{table:dsum1} and Table \ref{table:dsum2}.

We can conclude that: consectetur adipiscing elit. Aenean magna urna, sodales vel blandit sed, condimentum sit amet ante. Phasellus pulvinar ullamcorper porttitor. Cras vitae ipsum in magna condimentum malesuada ut at massa. Duis quis quam faucibus, euismod lacus sit amet, scelerisque odio.

```{r echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
dsum <- summary(nursery_data)
xtable(dsum[,1:5], caption = "\\tt Summary of Nursery Data Dataset, columns 1-5", label = "table:dsum1")
xtable(dsum[,6:9], caption = "\\tt Summary of Nursery Data Dataset, columns 6-9", label = "table:dsum2")
```
Distribution of Class attribute presented in Figure \ref{fig:classd}. Morbi volutpat augue vitae porta lobortis. Integer sit amet neque vel risus aliquam scelerisque et eget est. Cras maximus ex nec pharetra dictum. Vivamus vehicula ante sodales massa rhoncus, et blandit tortor interdum. Pellentesque aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r classd, fig.height=3, fig.width=5, fig.align="center", fig.cap="Distribution of Class attribute"}
prop.table((table(nursery_data$class)))
ggplot(nursery_data, aes(x=as.factor(class) )) + 
  geom_bar(aes(y= (..count..)/sum(..count..)),color="blue",fill=rgb(0.2,0,0.5)) +
  theme(legend.position = "none") +
  scale_y_continuous(labels=scales:::percent) +
  labs(x = "class",y="total")
```

The following code (Figure \ref{fig:classdp}) renders distribution of class attribute depending on parents attribute. Pellentesque aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r classdp, fig.height=3, fig.width=6, fig.align="center", fig.cap="Distribution of Class attribute depending on parents"}
ggplot(nursery_data,aes(x=factor(parents),fill=factor(class)))+
  geom_bar(position="dodge")
```

The following code (Figure \ref{fig:classdh}) renders distribution of class attribute depending on 'health' attribute. Pellentesque aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r classdh, fig.height=3, fig.width=6, fig.align="center", fig.cap="Distribution of Class attribute depending on health"}
nursery_data$health <- as.factor(nursery_data$health)
ggplot(data = nursery_data, mapping = aes(x = class, fill = health)) +
  geom_bar()
```
The following code (Figure \ref{fig:classdi}) renders distribution of class attribute depending on ''social' attribute. Pellentesque aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r classdi, fig.height=3, fig.width=6, fig.align="center", fig.cap="Distribution of Class attribute depending on income"}
ggplot(nursery_data, aes(social, fill=class)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9) +
  facet_wrap(~parents) + 
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=scales:::percent, breaks=seq(0,0.4,0.05)) +
  ylab("Percentage") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))

```
The following code (Figure \ref{fig:classdi}) renders distribution of 'class' attribute depending on 'nursery' attribute. Pellentesque aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r classdn, fig.height=5, fig.width=6, fig.align="center", fig.cap="Distribution of Class attribute depending on nursery"}
ggplot(nursery_data, aes(form, fill=class)) + 
  geom_bar(aes(y = (..count..)/sum(..count..)), alpha=0.9) +
  facet_wrap(~has_nurs) + 
  scale_fill_brewer(palette = "Dark2", direction = -1) +
  scale_y_continuous(labels=scales:::percent, breaks=seq(0,0.4,0.05)) +
  ylab("Percentage") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The conclusion is: aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

# Modeling
## Splitting the dataset into train and test

We are splitting the dataset in such a way, that train and test sets would have similar distribution of the 'class' attribute.

```{r}
train.rows<- createDataPartition(y= nursery_data$class, p=0.9, list = FALSE)
train.data<- nursery_data[train.rows,]
prop.table((table(train.data$class)))
```

```{r}
test.data<- nursery_data[-train.rows,]
prop.table((table(test.data$class)))
```

The following code (Figure \ref{fig:testd}) renders distribution of 'class' attribute depending on 'nursery' attribute. Pellentesque aliquam ligula eu justo porttitor, non fringilla erat vehicula. Pellentesque et dolor non nunc aliquet euismod. Vivamus vel malesuada lorem. Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r testd, fig.height=3, fig.width=6, fig.align="center", fig.cap="Distribution of Class attribute depending on nursery"}
ggplot(test.data, aes(x=as.factor(class))) + 
  geom_bar(aes(y = (..count..)/sum(..count..)),width=0.4,
  color="red", fill=rgb(0.9,1,0.7) )+theme(legend.position = "none") + 
  labs(x = "class",y="total")+scale_y_continuous(labels=scales:::percent)
```


## Decision Tree model fit

As a first step we will train a Desigion Tree model. This model is known to be computationally fast, but not very precise. We will use all default parameters and all attributes of thetrain dataset. Resuling tree is presented in Figure \ref{fig:dtree}. It shows that Fusce eget mauris a nulla sollicitudin eleifend eu auctor ligula. Sed nec dictum lorem. Vestibulum bibendum ultrices lorem, id fermentum felis tincidunt eu. Curabitur ipsum justo, dictum id finibus vitae, pulvinar non tortor. Curabitur vel mi a urna gravida commodo vitae vel libero. Maecenas imperdiet sed diam eget viverra.

```{r dtree, fig.align="center", fig.cap="Decision tree diagram", message=FALSE, warning=FALSE, paged.print=FALSE}
fitdt <- rpart(as.factor(class)~., method="class", data=train.data)
fancyRpartPlot(fitdt, main = "", sub = "")
```

## Decision Tree model evaluation
```{r }
dtPrediction <- predict(fitdt, test.data, type = "class")
```

```{r}
confMat <- table(dtPrediction,test.data$class)
confMat
accuracy <- sum(diag(confMat))/sum(confMat)
cat(sprintf("\nAccuracy=%f", accuracy))
```

## Random Forest model fit

```{r message=FALSE, warning=FALSE}
library(randomForest)
fitRF1 <- randomForest(as.factor(class)~.,
                      data=train.data, 
                      importance=TRUE, 
                      ntree=1000)
```

Importance of the dataset attributes for the prediction of the 'class' attribute shown in Figure \ref{fig:forimp}. Nam libero tempore, cum soluta nobis est eligendi optio cumque nihil impedit quo minus id quod maxime placeat facere possimus, omnis voluptas assumenda est, omnis dolor repellendus. Temporibus autem quibusdam et aut officiis debitis aut rerum necessitatibus saepe eveniet ut et voluptates repudiandae sint et molestiae non recusandae. Itaque earum rerum hic tenetur a sapiente delectus, ut aut reiciendis voluptatibus maiores alias consequatur aut perferendis doloribus asperiores repellat.

```{r forimp, fig.align="center", message=FALSE, warning=FALSE, paged.print=FALSE, fig.cap="Importance of the dataset attributes for the prediction of the 'class' attribute"}
varImpPlot(fitRF1, main="")
```

## Random Forest model prediction and evaluation

```{r}
PredictionRF1 <- predict(fitRF1, test.data)
head(PredictionRF1)
```

```{r}
confMat <- table(PredictionRF1,test.data$class)
confMat
accuracy <- sum(diag(confMat))/sum(confMat)
cat(sprintf("\nAccuracy=%f", accuracy))
```

# Dicsussion
Nor again is there anyone who loves or pursues or desires to obtain pain of itself, because it is pain, but because occasionally circumstances occur in which toil and pain can procure him some great pleasure. To take a trivial example, which of us ever undertakes laborious physical exercise, except to obtain some advantage from it? But who has any right to find fault with a man who chooses to enjoy a pleasure that has no annoying consequences, or one who avoids a pain that produces no resultant pleasure?"

# Conclusion
Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.

This file is only a basic article template. For full details of _The R Journal_ style and information on how to prepare your article for submission, see the [Instructions for Authors](https://journal.r-project.org/share/author-guide.pdf).
\bibliography{RJreferences}
